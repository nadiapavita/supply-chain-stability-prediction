# -*- coding: utf-8 -*-
"""Copy of SCRM_LSTM_balancing_augmentasi_reshape.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lcX8oMbCyfeWMsy6e4RvxuzCGU8WD2DA

# balancing robust
"""

# data train robust balanced = '/content/drive/MyDrive/SCRM/train_balancing_sc.csv'
# data train robust no balanced = '/content/drive/MyDrive/SCRM/train_no_balancing_sc_part3.csv'
# data train minmax no balanced = '/content/drive/MyDrive/SCRM/train_no_balancing_mm_part3.csv'
# data test robust = '/content/drive/MyDrive/SCRM/test_sc_part3.csv'
# data test minmax = '/content/drive/MyDrive/SCRM/test_mm_part3.csv'

import tensorflow as tf
print("GPU Available:", tf.config.list_physical_devices('GPU'))

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import EarlyStopping
from keras.layers import Dropout
from google.colab import drive
import pandas as pd

drive.mount('/content/drive')

# /content/drive/MyDrive/TA_warehouse/data_augmentasi_part1.csv
df = pd.read_csv('/content/drive/MyDrive/SCRM/train_balancing_sc.csv')

y = df['SCMstability_category'].values
X = df.drop('SCMstability_category', axis=1).values

features = X.shape[1] // 10

X = X.reshape(-1, 10, features)

# data = pd.read_csv('/content/drive/MyDrive/SCRM/train_balancing_sc.csv', delimiter=",")
data_validasi = pd.read_csv('/content/drive/MyDrive/SCRM/test_sc_part3.csv', delimiter=",")
# data.info()
data_validasi.info()

X_train = X
y_train = y
X_test = data_validasi.drop('SCMstability_category', axis=1)
y_test = data_validasi['SCMstability_category']

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

def make_sequences(X, y, timesteps=10):
    X_seq = []
    y_seq = []
    for i in range(len(X) - timesteps):
        X_seq.append(X[i:i+timesteps])
        y_seq.append(y[i+timesteps-1])
    return np.array(X_seq), np.array(y_seq)

X_test, y_test = make_sequences(X_test, y_test, timesteps=10)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

classifier = Sequential()

classifier.add(LSTM(units = 64, activation = 'tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))
classifier.add(Dropout(0.5))
classifier.add(Dense(units = 32, activation = 'relu'))
classifier.add(Dense(units = 5, activation = 'softmax'))

classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

early_stop = EarlyStopping(monitor='val_accuracy',patience=10,restore_best_weights=True,verbose=1)

classifier.fit(X_train, y_train, batch_size = 32, epochs = 100,verbose = 1, validation_split=0.2, callbacks=[early_stop], shuffle=False)

score, acc = classifier.evaluate(X_train, y_train, batch_size=10)
print('Train score:', score)
print('Train accuracy:', acc)

final_path = '/content/drive/MyDrive/SCRM/model_robust_balanced_part3.h5'
classifier.save(final_path)
print(f" beres udah kesimpen di {final_path}")

# testing
y_pred = classifier.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = y_test

print('*'*20)
score, acc = classifier.evaluate(X_test, y_test, batch_size=10)
print('Test score:', score)
print('Test accuracy:', acc)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_classes))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

plt.figure(figsize=(15, 6))
plt.plot(y_test_classes[:5000], label='Data Asli (Actual)', color='blue')
plt.plot(y_pred_classes[:5000], label='Prediksi Model', color='red', linestyle='--', alpha=0.7)

plt.title('Perbandingan Hasil Prediksi vs Data Asli (100 Data Pertama)')
plt.xlabel('Data ke- (Time Step)')
plt.ylabel('Kelas / Label')
plt.legend()
plt.show()

"""# balancing minmax"""

# data train robust balanced = '/content/drive/MyDrive/SCRM/train_balancing_sc.csv'
# data train robust no balanced = '/content/drive/MyDrive/SCRM/train_no_balancing_sc_part3.csv'
# data train minmax no balanced = '/content/drive/MyDrive/SCRM/train_no_balancing_mm_part3.csv'
# data train minmax balanced = '/content/drive/MyDrive/SCRM/train_balancing_mm.csv'
# data test robust = '/content/drive/MyDrive/SCRM/test_sc_part3.csv'
# data test minmax = '/content/drive/MyDrive/SCRM/test_mm_part3.csv'

import tensorflow as tf
print("GPU Available:", tf.config.list_physical_devices('GPU'))

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import EarlyStopping
from keras.layers import Dropout
from google.colab import drive
import pandas as pd

drive.mount('/content/drive')

# /content/drive/MyDrive/TA_warehouse/data_augmentasi_part1.csv
df = pd.read_csv('/content/drive/MyDrive/SCRM/train_balancing_mm.csv')

y = df['SCMstability_category'].values
X = df.drop('SCMstability_category', axis=1).values

features = X.shape[1] // 10

X = X.reshape(-1, 10, features)

# data = pd.read_csv('/content/drive/MyDrive/SCRM/train_balancing_sc.csv', delimiter=",")
data_validasi = pd.read_csv('/content/drive/MyDrive/SCRM/test_mm_part3.csv', delimiter=",")
# data.info()
data_validasi.info()

X_train = X
y_train = y
X_test = data_validasi.drop('SCMstability_category', axis=1)
y_test = data_validasi['SCMstability_category']

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

def make_sequences(X, y, timesteps=10):
    X_seq = []
    y_seq = []
    for i in range(len(X) - timesteps):
        X_seq.append(X[i:i+timesteps])
        y_seq.append(y[i+timesteps-1])
    return np.array(X_seq), np.array(y_seq)

X_test, y_test = make_sequences(X_test, y_test, timesteps=10)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

classifier = Sequential()

classifier.add(LSTM(units = 64, activation = 'tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))
classifier.add(Dropout(0.5))
classifier.add(Dense(units = 32, activation = 'relu'))
classifier.add(Dense(units = 5, activation = 'softmax'))

classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

early_stop = EarlyStopping(monitor='val_accuracy',patience=10,restore_best_weights=True,verbose=1)

classifier.fit(X_train, y_train, batch_size = 32, epochs = 100,verbose = 1, validation_split=0.2, callbacks=[early_stop], shuffle=False)

score, acc = classifier.evaluate(X_train, y_train, batch_size=10)
print('Train score:', score)
print('Train accuracy:', acc)

final_path = '/content/drive/MyDrive/SCRM/model_minmax_balanced_part3.h5'
classifier.save(final_path)
print(f" beres udah kesimpen di {final_path}")

# testing
y_pred = classifier.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = y_test

print('*'*20)
score, acc = classifier.evaluate(X_test, y_test, batch_size=10)
print('Test score:', score)
print('Test accuracy:', acc)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_classes))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

plt.figure(figsize=(15, 6))
plt.plot(y_test_classes[:5000], label='Data Asli (Actual)', color='blue')
plt.plot(y_pred_classes[:5000], label='Prediksi Model', color='red', linestyle='--', alpha=0.7)

plt.title('Perbandingan Hasil Prediksi vs Data Asli (100 Data Pertama)')
plt.xlabel('Data ke- (Time Step)')
plt.ylabel('Kelas / Label')
plt.legend()
plt.show()